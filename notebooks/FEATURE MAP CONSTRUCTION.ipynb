{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import os\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import h5py\n",
    "import math\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from numba import cuda \n",
    "from tensorflow.keras import Model\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tiling.read_tiles import TissueDataset, load_color_normalization_values\n",
    "from tiling.preprocessing.processing import split_whole_slide\n",
    "from tiling.preprocessing.datamodel import SlideManager, Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code snippet nvidia gpu\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "HDF5_FOLDER = '/media/nico/data/fourthbrain/project/training_CAMELYON16'\n",
    "green_layer_only = False\n",
    "color_normalization_file=\"/home/nico/Documents/FourthBrainBreastCancer/tiling/CAMELYON16_color_normalization.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE MAP CONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIRST GET TILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAM_BASE_DIR = '/media/nico/data/fourthbrain/project/'\n",
    "CAM16_DIR = CAM_BASE_DIR + 'CAMELYON16/'\n",
    "color_normalization_file=\"/home/nico/Documents/FourthBrainBreastCancer/tiling/CAMELYON16_color_normalization.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mgr = SlideManager(cam16_dir=CAM16_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "level = 3\n",
    "tile_size=256\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/media/nico/data/fourthbrain/project/model_testing/model_inceptionv3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL TILES HAVE DIFFERENT DIMENSIONS - WE NEED TO FEED A FEATURE MATRIX OF THE SAME SIZE IN THE UNET\n",
    "# SO WE ARE GOING TO LOOK FIND THE WIDEST AND HIGHEST SLIDES IN OUR DATASETS FIRST\n",
    "# FROM THE PAPER : \"however the sizes of WSIs differ. Therefore we first prepare a white map of sufficient size filled with zeroes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_2dim(mgr):\n",
    "    w, h = 0, 0\n",
    "    for sl in mgr.test_slides:\n",
    "        (wt, ht) = sl.level_dimensions[level]\n",
    "        w = wt if wt> w else w\n",
    "        h = ht if ht> w else h\n",
    "\n",
    "    for sl in mgr.annotated_slides:\n",
    "        (wt, ht) = sl.level_dimensions[level]\n",
    "        w = wt if wt> w else w\n",
    "        h = ht if ht> w else h\n",
    "\n",
    "    for sl in mgr.negative_slides:\n",
    "        (wt, ht) = sl.level_dimensions[level]\n",
    "        w = wt if wt> w else w\n",
    "        h = ht if ht> w else h\n",
    "\n",
    "    wf = int(w / tile_size)\n",
    "    wf += 1 if w % tile_size != 0 else 0\n",
    "    \n",
    "    hf = int(h / tile_size)\n",
    "    hf += 1 if h % tile_size != 0 else 0\n",
    "    \n",
    "    return (w, h),(wf, hf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_3_max_size, level_3_features_eq = features_2dim(mgr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27648, 27712), (108, 109))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "level_3_max_size, level_3_features_eq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_map = 128 #max(level_3_features_eq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### ALRIGHT THE FEATURES MAP WILL BE max(wf, hf) so for a 256 tile 109 x 109 \n",
    "### LET'S USE A MULTIPLE OF 128 FOR NOW SO THAT IT FITS OUR UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model layer\n",
    "# take the avg pooling before dense layer\n",
    "layer_output = model.layers[-2].output\n",
    "feature_model = Model(inputs=model.input, outputs=layer_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_output.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_FEATURES = '/media/nico/data/fourthbrain/project/training_CAMELYON16_features/'\n",
    "\n",
    "slide = mgr.annotated_slides[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pack it all together\n",
    "dim_map = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start with tumor_001 - 2021-01-28 12:40:00.278184\n",
      "start with tumor_002 - 2021-01-28 12:40:00.278289\n",
      "start with tumor_003 - 2021-01-28 12:40:00.278383\n",
      "start with tumor_004 - 2021-01-28 12:40:00.278408\n",
      "start with tumor_005 - 2021-01-28 12:40:00.278424\n",
      "start with tumor_006 - 2021-01-28 12:40:00.278484\n",
      "start with tumor_007 - 2021-01-28 12:40:00.278502\n",
      "start with tumor_008 - 2021-01-28 12:40:00.278520\n",
      "start with tumor_009 - 2021-01-28 12:40:00.278540\n",
      "start with tumor_010 - 2021-01-28 12:40:00.278561\n",
      "start with tumor_011 - 2021-01-28 12:40:00.278652\n",
      "start with tumor_012 - 2021-01-28 12:40:00.278672\n",
      "start with tumor_013 - 2021-01-28 12:40:00.278687\n",
      "start with tumor_014 - 2021-01-28 12:40:00.278701\n",
      "start with tumor_015 - 2021-01-28 12:40:00.278715\n",
      "start with tumor_016 - 2021-01-28 12:40:00.278729\n",
      "start with tumor_017 - 2021-01-28 12:40:00.278743\n",
      "start with tumor_018 - 2021-01-28 12:40:00.278757\n",
      "start with tumor_019 - 2021-01-28 12:40:00.278770\n",
      "start with tumor_020 - 2021-01-28 12:40:00.278785\n",
      "start with tumor_021 - 2021-01-28 12:40:00.278799\n",
      "start with tumor_022 - 2021-01-28 12:40:00.278812\n",
      "start with tumor_023 - 2021-01-28 12:40:00.278826\n",
      "start with tumor_024 - 2021-01-28 12:40:00.278840\n",
      "done with tumor_024 - 2021-01-28 12:42:51.968063\n",
      "start with tumor_025 - 2021-01-28 12:42:51.968154\n",
      "done with tumor_025 - 2021-01-28 12:46:11.286047\n",
      "start with tumor_026 - 2021-01-28 12:46:11.286126\n",
      "done with tumor_026 - 2021-01-28 12:52:24.069045\n",
      "start with tumor_027 - 2021-01-28 12:52:24.069126\n",
      "done with tumor_027 - 2021-01-28 12:55:16.885620\n",
      "start with tumor_028 - 2021-01-28 12:55:16.885693\n",
      "done with tumor_028 - 2021-01-28 12:58:10.895152\n",
      "start with tumor_029 - 2021-01-28 12:58:10.895232\n",
      "done with tumor_029 - 2021-01-28 13:01:19.153436\n",
      "start with tumor_030 - 2021-01-28 13:01:19.153506\n",
      "done with tumor_030 - 2021-01-28 13:04:13.212693\n",
      "start with tumor_031 - 2021-01-28 13:04:13.212767\n",
      "done with tumor_031 - 2021-01-28 13:09:58.674159\n",
      "start with tumor_032 - 2021-01-28 13:09:58.674243\n",
      "done with tumor_032 - 2021-01-28 13:12:49.854123\n",
      "start with tumor_033 - 2021-01-28 13:12:49.854195\n",
      "done with tumor_033 - 2021-01-28 13:16:09.123010\n",
      "start with tumor_034 - 2021-01-28 13:16:09.123082\n",
      "done with tumor_034 - 2021-01-28 13:20:20.487344\n",
      "start with tumor_035 - 2021-01-28 13:20:20.487417\n",
      "done with tumor_035 - 2021-01-28 13:23:07.969817\n",
      "start with tumor_036 - 2021-01-28 13:23:07.969890\n",
      "done with tumor_036 - 2021-01-28 13:26:48.503688\n",
      "start with tumor_037 - 2021-01-28 13:26:48.503762\n",
      "done with tumor_037 - 2021-01-28 13:30:01.562669\n",
      "start with tumor_038 - 2021-01-28 13:30:01.562741\n",
      "done with tumor_038 - 2021-01-28 13:33:12.295703\n",
      "start with tumor_039 - 2021-01-28 13:33:12.295779\n",
      "done with tumor_039 - 2021-01-28 13:39:24.113043\n",
      "start with tumor_040 - 2021-01-28 13:39:24.113115\n",
      "done with tumor_040 - 2021-01-28 13:42:06.346295\n",
      "start with tumor_041 - 2021-01-28 13:42:06.346367\n",
      "done with tumor_041 - 2021-01-28 13:44:54.500136\n",
      "start with tumor_042 - 2021-01-28 13:44:54.500212\n",
      "done with tumor_042 - 2021-01-28 13:48:06.467827\n",
      "start with tumor_043 - 2021-01-28 13:48:06.467901\n",
      "done with tumor_043 - 2021-01-28 13:50:51.375710\n",
      "start with tumor_044 - 2021-01-28 13:50:51.375782\n",
      "done with tumor_044 - 2021-01-28 13:57:32.151305\n",
      "start with tumor_045 - 2021-01-28 13:57:32.151532\n",
      "done with tumor_045 - 2021-01-28 14:00:21.345325\n",
      "start with tumor_046 - 2021-01-28 14:00:21.345398\n",
      "done with tumor_046 - 2021-01-28 14:06:54.443633\n",
      "start with tumor_047 - 2021-01-28 14:06:54.443704\n",
      "done with tumor_047 - 2021-01-28 14:11:53.742260\n",
      "start with tumor_048 - 2021-01-28 14:11:53.742331\n",
      "done with tumor_048 - 2021-01-28 14:14:35.713042\n",
      "start with tumor_049 - 2021-01-28 14:14:35.713114\n",
      "done with tumor_049 - 2021-01-28 14:17:26.648449\n",
      "start with tumor_050 - 2021-01-28 14:17:26.648678\n",
      "done with tumor_050 - 2021-01-28 14:20:26.985739\n",
      "start with tumor_051 - 2021-01-28 14:20:26.985816\n",
      "done with tumor_051 - 2021-01-28 14:23:51.800353\n",
      "start with tumor_052 - 2021-01-28 14:23:51.800431\n",
      "done with tumor_052 - 2021-01-28 14:26:58.550829\n",
      "start with tumor_053 - 2021-01-28 14:26:58.550911\n",
      "done with tumor_053 - 2021-01-28 14:29:48.548944\n",
      "start with tumor_054 - 2021-01-28 14:29:48.549014\n",
      "done with tumor_054 - 2021-01-28 14:36:08.310947\n",
      "start with tumor_055 - 2021-01-28 14:36:08.311021\n",
      "done with tumor_055 - 2021-01-28 14:41:58.093121\n",
      "start with tumor_056 - 2021-01-28 14:41:58.094193\n",
      "done with tumor_056 - 2021-01-28 14:45:36.684585\n",
      "start with tumor_057 - 2021-01-28 14:45:36.684795\n",
      "done with tumor_057 - 2021-01-28 14:48:38.279549\n",
      "start with tumor_058 - 2021-01-28 14:48:38.279623\n",
      "done with tumor_058 - 2021-01-28 14:52:50.607508\n",
      "start with tumor_059 - 2021-01-28 14:52:50.607585\n",
      "done with tumor_059 - 2021-01-28 14:55:37.270748\n",
      "start with tumor_060 - 2021-01-28 14:55:37.270821\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-0710e934037b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#         coords.append(coord)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m#         slide_locations.append(slide_location)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mfeature_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtile_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfeatures_map\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnp_features_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoord\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1638\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1639\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1640\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1642\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;31m# input pipeline graph serialization and deserialization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_optimization\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_default_optimizations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shuffle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m       \u001b[0;31m# See b/141490660 for more details.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/data/util/options.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m       \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/nightly/lib/python3.7/site-packages/tensorflow/python/data/util/options.py\u001b[0m in \u001b[0;36mget_fn\u001b[0;34m(option)\u001b[0m\n\u001b[1;32m     82\u001b[0m   \"\"\"\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m   \u001b[0;32mdef\u001b[0m \u001b[0mget_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moption\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for slide in mgr.annotated_slides:\n",
    "    i += 1\n",
    "    print('start with {} - {}'.format(slide.name, datetime.now()))\n",
    "    if int(slide.name[-2:]) < 24:\n",
    "        continue\n",
    "    iter_whole_slide = split_whole_slide(slide, level=level, tile_size=tile_size, color_normalization_file=color_normalization_file, verbose=False)\n",
    "    tiles, labels, coords, slide_locations, features_map = list(), list(), list(), list(), list()\n",
    "    np_features_map = np.zeros((dim_map, dim_map, layer_output.shape[1]))\n",
    "    np_labels_map = np.zeros((dim_map, dim_map, 1))\n",
    "    y_preds, layer_outputs = list(), list()\n",
    "\n",
    "    for tile, label, coord, slide_location in iter_whole_slide:\n",
    "#         tiles.append(tile)\n",
    "#         labels.append(label)\n",
    "#         coords.append(coord)\n",
    "#         slide_locations.append(slide_location)\n",
    "        feature_map = feature_model.predict(tile.reshape(1,tile_size,tile_size,3))\n",
    "        features_map.append(feature_map)\n",
    "        np_features_map[coord[0], coord[1],:] = feature_map\n",
    "        np_labels_map[coord[0], coord[1],:] = label\n",
    "    dct = {\n",
    "    #     'tiles': tiles,\n",
    "    #     'labels': labels,\n",
    "    #     'coords': coords,\n",
    "    #     'slide_locations': slide_locations,\n",
    "    #     'features_map': features_map,\n",
    "        'np_features_map': np_features_map,\n",
    "        'np_labels_map': np_labels_map\n",
    "    }\n",
    "#     hf = h5py.File('data.h5', 'w')\n",
    "#     hf.create_dataset('dataset_{}'/format(i), data=dct)\n",
    "    with open(os.path.join(PATH_FEATURES, \"{}.pkl\".format(slide.name)), 'wb') as handle:\n",
    "        pickle.dump(dct, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    print('done with {} - {}'.format(slide.name, datetime.now()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
